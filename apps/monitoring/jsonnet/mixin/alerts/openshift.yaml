groups:
- name: openshift.rules
  rules:
    - alert: HighlyAvailableWorkloadIncorrectlySpread
      # Adapted from https://github.com/openshift/cluster-monitoring-operator/blob/a54da59654385fc1a62e9ca5a2cf8ee8dd9fa3cd/assets/cluster-monitoring-operator/prometheus-rule.yaml
      annotations:
        description: Workload {{ $labels.namespace }}/{{ $labels.workload }} is incorrectly
          spread across multiple nodes which breaks high-availability requirements.
          Since the workload is using persistent volumes, manual intervention is needed.
          Please follow the guidelines provided in the runbook of this alert to fix
          this issue.
        runbook_url: https://github.com/openshift/runbooks/blob/master/alerts/HighlyAvailableWorkloadIncorrectlySpread.md
        summary: Highly-available workload is incorrectly spread across multiple nodes
          and manual intervention is needed.
      expr: |
        count without (node)
        (
          group by (node, workload, namespace)
          (
            kube_pod_info{node!=""}
            * on(namespace,pod) group_left(workload)
            (
              kube_pod_spec_volumes_persistentvolumeclaims_info
              * on(namespace,pod) group_left(workload)
              (
                namespace_workload_pod:kube_pod_owner:relabel
                * on(namespace,workload,workload_type) group_left()
                (
                  count without(pod) (namespace_workload_pod:kube_pod_owner:relabel{namespace=~"(openshift-.*|kube-.*|default)"}) > 1
                )
              )
            )
          )
        ) == 1
      for: 1h
      labels:
        severity: warning
    - alert: MultipleContainersOOMKilled
      # Adapted from https://github.com/openshift/cluster-monitoring-operator/blob/df9329e810f53771a5ef70f995593f4a545c1071/jsonnet/rules.libsonnet#L416-L430
      expr: |
        sum(
          max by(namespace, container, pod) (
            increase(kube_pod_container_status_restarts_total[12m])
          )
          and
          max by(namespace, container, pod) (
            kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}
          ) == 1
        ) > 2
      'for': '15m'
      annotations:
        summary: 'Containers are being killed due to OOM'
        description: Multiple containers were out of memory killed within the past 15 minutes.
          There are many potential causes of OOM errors, however issues on a specific node or containers breaching their limits is common.'
      labels:
        severity: 'info'
