# Flux Kustomization deletion lead to all application deletion

## Incident date

Start: 2020-06-09 19:17
End: 2020-06-10 17:01

## Author

- paulfantom

## Status

Complete

## Summary

Deletion of `Kustomization` object responsible for managing `flux` lead to cascading deletion of all `Kustomization`
objects. Which in turn lead to deletion of all applications inside a cluster due to setting `purge: true`.

## Impact

All applications were inaccessible for extended period of time (varying from 1.5h to 15h). 

## Root Causes

- Human error due to lack of enough expertise with flux ecosystem.

## Trigger

Deletion of Kustomization responsible for objects in `flux-system` namespace. This triggered cascading deletion of all resources.

## Resolution

Cluster recreation from backups.

## Detection

Event was detected instantly by checking for resources in `flux-system` namespace. Alerts also started firing after few minutes.

## Action items
- Kustomization for 'flux' shouldn't include other Kustomizations to prevent cascading deletion issue
- SealedSecret master key needs to be periodically checked
- encryptedData from SealedSecrets should be stored in settings.yaml and SealedSecrets should be build in jsonnet. This would allow creating a script for faster credentials rotation. Script should be used periodically.
- nextcloud database backup mechanism needs to be checked to figure out why backups weren't created
- plex backups need to be performed and validated
- [optional] core metrics should be sent to external metrics store
- [optional] PXE boot arm64 hosts

## Lessons Learned

### What went well

- Ansible roles started cluster without any hiccups

### What went wrong

- Backups were not tested and sometimes not present (for example plex)
- master key for SealedSecret was corrupted and this wasn't caught up earlier
- Node cleanup went very slow and had to be done without any SOP

### Where we got lucky

- Nextcloud database wasn't updated for last 9 days, so even older backup could fully restore service.

## Timeline

All times in CST

| Time  | Description |
|-------|-------------|
| 19:17 | Detection of incorrect resource deletion
| 19:21 | Attempt to recover flux-system namespace
| 19:23 | Noticed kubernetes finalizers at play and that API server will possible delete all resources
| 19:24 | Created `Critical` incident on Statuspage
| 19:35 | Detection of additional resources being deleted
| 19:40 | All resources were deleted in a cluster
| 19:49 | Decision to discard whole cluster and start from scratch
| 19:51 | Started clearing up nodes
| 19:58 | Noticed Ansible playbooks were outdated.
| 20:01 | Planning additional actions regarding cluster upgrade. Decision to upgrade to 1.21 and update ansible code.
| 20:54 | Node cleanup successful. Starting ansible run
| 21:13 | Ansible run completed, k3s cluster active. Starting deploying base components inside a cluster.
| 21:22 | First try at master key recovery for SealedSecrets
| 21:54 | Master key for SealedSecrets turns out to be broken. Decision to roll over all credentials.
| 22:07 | Base components (without flux) successfully rolled out. Starting deploying applications
| 22:10 | Homer is up and running.
| 22:11 | Setting "portal" to `operational` on statuspage
| 22:10 | Cookbook is up and running
| 22:45 | HomeAssistant is up and running.
| 22:46 | Setting "homeassistant" to `operational` on statuspage
| 22:50 | blogs are up and running
| 22:56 | adblocker is up and running
| 23:01 | kured is up and running
| 23:02 | Issues with Ingress certificates detected.
| 23:39 | Stopped with further deployments due to late hour.
| 00:00 | **2020-06-10**
| 07:51 | updated metallb to 0.10.0 to reduce number of necessary SealedSecrets
| 10:01 | monitoring is up. Setting "grafana" component to `operational` on Statuspage
| 11:54 | Lack of current mysql backups for nextcloud database detected. Last one is from 2021-05-31.
| 12:32 | Database recovery successful. Starting nextcloud update to update database
| 12:51 | Cloud is up and running. Setting "cloud" to `operational` on statuspage. Incident is no longer considered `Critical`.
| 13:17 | Started work on recovering multimedia services
| 13:21 | Detected lack of backups for current plex library. Found last backup from November 28, 2020.
| 14:53 | Ombi is up and running
| 15:53 | Radarr, Sonarr, and their respective exportarrs are running
| 16:04 | Transmission up and running
| 16:21 | Plex backup is corrupted and there is no possibility of recovering data. Starting plex from scratch
| 16:31 | Plex started scanning library
| 16:50 | Plex has started, but there are issues with connecting to plex from internet. Investigating.
| 17:01 | Issues were resolved. OUTAGE ENDS
